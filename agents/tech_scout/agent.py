import os
import feedparser
from google.adk.agents import Agent
from google.adk.models.lite_llm import LiteLlm

# ==========================================
# 0. ç½‘ç»œä¸ä»£ç†é…ç½® (è®¿é—® Reddit/OpenAI å¿…éœ€)
# ==========================================
# è¯·æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ç«¯å£å· (Clashé€šå¸¸æ˜¯7890)
# å¦‚æœä½ åœ¨æœåŠ¡å™¨ç¯å¢ƒæˆ–å·²ç»å…¨å±€ä»£ç†ï¼Œå¯æ³¨é‡Šæ‰è¿™ä¸¤è¡Œ
os.environ["http_proxy"] = "http://127.0.0.1:7890"
os.environ["https_proxy"] = "http://127.0.0.1:7890"

# ==========================================
# 1. å®šä¹‰ RSS æ•°æ®æºåº“
# ==========================================

# 1.1 ç”¨æˆ·å®šä¹‰çš„é«˜è´¨é‡æº
RSS_SOURCES = [
    {
        "keys": ["hf", "huggingface", "hugging face"],
        "name": "Hugging Face åšå®¢",
        "url": "https://huggingface.co/blog/feed.xml",
        "desc": "åŒ…å«æœ€æ–°çš„AIæ¨¡å‹å’ŒæŠ€æœ¯å‘å¸ƒ"
    },
    {
        "keys": ["reddit", "reddit ml", "æœºå™¨å­¦ä¹ "],
        "name": "Reddit MachineLearning",
        "url": "https://www.reddit.com/r/MachineLearning/.rss",
        "desc": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º"
    },
    {
        "keys": ["mit", "tech review", "ç§‘æŠ€è¯„è®º"],
        "name": "MIT Tech Review",
        "url": "https://www.technologyreview.com/feed/",
        "desc": "MITç§‘æŠ€è¯„è®ºç§‘æŠ€æ–°é—»"
    },
    {
        "keys": ["openai", "oa"],
        "name": "OpenAI åšå®¢",
        "url": "https://openai.com/blog/rss.xml",
        "desc": "OpenAIå®˜æ–¹åšå®¢"
    },
    {
        "keys": ["deepmind", "google ai"],
        "name": "DeepMind åšå®¢",
        # ä¿®æ­£äº† DeepMind æœ€æ–°çš„ RSS åœ°å€ï¼Œæ—§åœ°å€å¯èƒ½å¤±æ•ˆ
        "url": "https://deepmind.google/blog/rss/index.xml", 
        "desc": "DeepMind/Google DeepMind å®˜æ–¹åšå®¢"
    },
    # ä¿ç•™ä¹‹å‰çš„ä¸­æ–‡ä¼˜è´¨æºï¼Œåšä¸ªæ··åˆåŒæ‰“
    {
        "keys": ["36kr", "36æ°ª"],
        "name": "36æ°ª",
        "url": "https://36kr.com/feed",
        "desc": "ä¸­å›½å•†ä¸šç§‘æŠ€æ–°é—»"
    },
    {
        "keys": ["qbit", "é‡å­ä½"],
        "name": "é‡å­ä½",
        "url": "https://www.qbitai.com/feed",
        "desc": "ä¸­æ–‡ AI å‚ç›´åª’ä½“"
    }
]

# ==========================================
# 2. å®šä¹‰å·¥å…·
# ==========================================

def rss_reader_tool(query: str) -> str:
    """
    æ ¹æ®å…³é”®è¯æˆ– URL è·å– RSS è®¢é˜…æºçš„æœ€æ–°å†…å®¹ã€‚
    
    Args:
        query: åª’ä½“åç§°å…³é”®è¯ï¼ˆå¦‚ "OpenAI", "Reddit", "36kr"ï¼‰æˆ–ç›´æ¥çš„ URLã€‚
    """
    query = query.lower().strip()
    target_url = None
    source_name = "æœªçŸ¥æ¥æº"

    print(f"\n[Tool] ç”¨æˆ·æŸ¥è¯¢ RSS: {query} ...")

    # --- 1. æ™ºèƒ½åŒ¹é…é€»è¾‘ ---
    # å¦‚æœè¾“å…¥çš„æ˜¯ http å¼€å¤´çš„ï¼Œç›´æ¥ç”¨
    if query.startswith("http"):
        target_url = query
        source_name = "è‡ªå®šä¹‰URL"
    else:
        # éå†æˆ‘ä»¬çš„æºåˆ—è¡¨è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
        for source in RSS_SOURCES:
            # æ£€æŸ¥ keys åˆ—è¡¨æˆ– name å­—æ®µ
            if query in source["keys"] or query in source["name"].lower():
                target_url = source["url"]
                source_name = source["name"]
                print(f"[Tool] å‘½ä¸­é¢„è®¾æº: {source_name}")
                break
        
        # å¦‚æœæ²¡åŒ¹é…åˆ°ï¼Œåšä¸€ä¸ªé»˜è®¤å›è½ï¼ˆOptionalï¼‰
        if not target_url:
            if "ai" in query or "æ¨¡å‹" in query:
                # é»˜è®¤çœ‹ Hugging Face
                target_url = "https://huggingface.co/blog/feed.xml"
                source_name = "Hugging Face (è‡ªåŠ¨æ¨è)"
            else:
                available_keys = ", ".join([s["name"] for s in RSS_SOURCES])
                return f"æœªæ‰¾åˆ°åŒ¹é…çš„æºã€‚æ”¯æŒçš„æºåŒ…æ‹¬ï¼š{available_keys}ã€‚æˆ–è€…è¯·ç›´æ¥æä¾› URLã€‚"

    # --- 2. è§£æé€»è¾‘ ---
    try:
        # å¢åŠ  timeout é˜²æ­¢å¡æ­»
        # agent è¿™é‡Œçš„ User-Agent å¾ˆé‡è¦ï¼Œæœ‰äº›ç½‘ç«™ï¼ˆå¦‚ Redditï¼‰ä¼šæ‹¦æˆªé»˜è®¤ UA
        feed = feedparser.parse(
            target_url, 
            agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko)"
        )
        
        if feed.bozo and feed.bozo_exception:
            print(f"[Tool Warning] è§£æç”±é”™è¯¯ä½†å°è¯•ç»§ç»­: {feed.bozo_exception}")

        if not feed.entries:
            return f"æˆåŠŸè¿æ¥åˆ° {source_name}ï¼Œä½†æ²¡æœ‰å‘ç°æ–‡ç« å†…å®¹ï¼ˆå¯èƒ½æ˜¯åçˆ¬è™«æ‹¦æˆªæˆ–æºä¸ºç©ºï¼‰ã€‚"

        # --- 3. æ ¼å¼åŒ–è¾“å‡º ---
        entries_data = []
        # è·å–å‰ 5 ç¯‡å³å¯ï¼ŒReddit å†…å®¹å¯èƒ½å¾ˆé•¿
        for entry in feed.entries[:5]:
            title = entry.get("title", "æ— æ ‡é¢˜")
            link = entry.get("link", "")
            # å¤„ç†æ‘˜è¦ï¼šç§»é™¤å¤šä½™ HTML æ ‡ç­¾ï¼Œæˆªæ–­
            summary = entry.get("summary", entry.get("description", ""))
            # ç®€å•çš„æ¸…æ´— HTML æ ‡ç­¾ (ä¹Ÿå¯å¼•å…¥ BeautifulSoupï¼Œè¿™é‡Œç”¨ç®€å•åˆ‡ç‰‡ä»£æ›¿)
            summary_clean = summary.replace("<p>", "").replace("</p>", "").replace("<br>", "\n")[:250]
            
            entries_data.append(f"ğŸ“Œ {title}\nğŸ”— {link}\nğŸ“ {summary_clean}...")
            
        result_text = f"ã€æ¥æºï¼š{source_name}ã€‘\næœ€æ–°æ–‡ç« åˆ—è¡¨ï¼š\n" + "\n\n".join(entries_data)
        return result_text

    except Exception as e:
        return f"è¯»å– RSS å¤±è´¥ ({source_name}): {str(e)}\nè¯·æ£€æŸ¥ç½‘ç»œè¿é€šæ€§æˆ–ä»£ç†è®¾ç½®ã€‚"

# ==========================================
# 3. é…ç½® LiteLLM
# ==========================================
# ç¡®ä¿ .env æ–‡ä»¶é…ç½®æ­£ç¡®
api_base = os.environ.get("IFLOW_API_BASE")
api_key = os.environ.get("IFLOW_API_KEY")
model_name = os.environ.get("MODELNAME") # ç¡®ä¿è¿™ä¸ªæ¨¡å‹å­˜åœ¨

os.environ["OPENAI_API_BASE"] = api_base
os.environ["OPENAI_API_KEY"] = api_key

custom_model = LiteLlm(
    model=f"openai/{model_name}",
    temperature=0.3
)

# ==========================================
# 4. Agent å®šä¹‰
# ==========================================

# åŠ¨æ€ç”Ÿæˆæ”¯æŒåˆ—è¡¨å­—ç¬¦ä¸²ï¼Œæ”¾å…¥ Prompt ä¸­ï¼Œè¿™æ · LLM å°±çŸ¥é“å®ƒèƒ½æŸ¥ä»€ä¹ˆ
source_list_str = "\n".join([f"- {s['name']}: {s['desc']}" for s in RSS_SOURCES])

instruction = f"""
ä½ æ˜¯ä¸€ä¸ªã€å…¨çƒå‰æ²¿ç§‘æŠ€æƒ…æŠ¥å®˜ã€‘ï¼Œä¸“æ³¨äº AI å’Œç§‘æŠ€é¢†åŸŸçš„è¶‹åŠ¿åˆ†æã€‚
ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯é€šè¿‡ RSS å·¥å…·è¯»å–æœ€æ–°çš„åšå®¢å’Œæ–°é—»ã€‚

ã€æ”¯æŒçš„æƒå¨æ•°æ®æºã€‘ï¼š
{source_list_str}

ã€å·¥ä½œæµç¨‹ã€‘ï¼š
1. å½“ç”¨æˆ·è¯¢é—®æŸä¸ªç‰¹å®šæœºæ„ï¼ˆå¦‚ OpenAI, DeepMindï¼‰æˆ–è¯é¢˜ï¼ˆå¦‚ "Reddit ä¸Šåœ¨è®¨è®ºä»€ä¹ˆ"ï¼‰æ—¶ï¼Œè°ƒç”¨ `rss_reader_tool`ã€‚
2. å³ä½¿å³ä½¿ç”¨æˆ·æ²¡æœ‰æ˜ç¡®è¯´åå­—ï¼Œæ¯”å¦‚é—®â€œæœ€è¿‘ AI æœ‰ä»€ä¹ˆçªç ´â€ï¼Œä½ ä¹Ÿåº”è¯¥ä¸»åŠ¨å»æŸ¥é˜… Hugging Face æˆ– MIT Tech Reviewã€‚
3. **è¾“å‡ºè¦æ±‚**ï¼š
   - å…ˆåˆ—å‡ºä½ æŸ¥é˜…äº†å“ªäº›æºã€‚
   - å¯¹è·å–çš„æ–‡ç« è¿›è¡Œ**æ€»ç»“**ï¼Œä¸è¦åªæ˜¯ç½—åˆ—æ ‡é¢˜ã€‚
   - æå–å‡º**æ ¸å¿ƒæ´å¯Ÿ**ï¼ˆKey Insightsï¼‰ã€‚
   - å¦‚æœæ˜¯è‹±æ–‡æºï¼Œè¯·å°†æ ¸å¿ƒå†…å®¹**ç¿»è¯‘ä¸ºä¸­æ–‡**è¾“å‡ºã€‚
   - ç»™å‡ºæ¯ä¸ªæ–‡ç« çš„è®¿é—®åœ°å€ã€‚

è¯·ä¿æŒä¸“ä¸šã€å®¢è§‚ã€æ•é”ã€‚
"""

root_agent = Agent(
    name="tech_scout",
    model=custom_model,
    instruction=instruction,
    tools=[rss_reader_tool]
)